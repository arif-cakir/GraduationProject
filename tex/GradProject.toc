\babel@toc {american}{}\relax 
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}%
\contentsline {section}{\numberline {2}Autoencoders}{3}{section.2}%
\contentsline {subsubsection}{\numberline {2.0.1}Skip-Gram Algorithm}{4}{subsubsection.2.0.1}%
\contentsline {subsubsection}{\numberline {2.0.2}Continuous Bag of Words}{6}{subsubsection.2.0.2}%
\contentsline {section}{\numberline {3}Word Embedding Techniques}{8}{section.3}%
\contentsline {subsection}{\numberline {3.1}Term Frequency - Inverse Document Frequency}{9}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Word2Vec}{9}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Global Vectors for Word Representation}{10}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Bidirectional Encoder Representations from Transformers}{11}{subsection.3.4}%
\contentsline {section}{\numberline {4}Application}{13}{section.4}%
\contentsline {subsection}{\numberline {4.1}Information About the Dataset}{14}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Preparation of the Dataset}{14}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Skip-Gram Algorithm}{15}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Continuous Bag of Words}{15}{subsection.4.4}%
\contentsline {section}{\numberline {5}Analysis and Visualization}{15}{section.5}%
\contentsline {section}{\numberline {6}Discussion}{15}{section.6}%
