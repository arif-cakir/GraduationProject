\babel@toc {american}{}\relax 
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}%
\contentsline {section}{\numberline {2}Word Embedding Techniques}{3}{section.2}%
\contentsline {subsection}{\numberline {2.1}Term Frequency - Inverse Document Frequency}{4}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Word2Vec}{5}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Skip-Gram Algorithm}{5}{subsubsection.2.2.1}%
\contentsline {subsubsection}{\numberline {2.2.2}Continuous Bag of Words}{7}{subsubsection.2.2.2}%
\contentsline {subsection}{\numberline {2.3}Global Vectors for Word Representation}{9}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Bidirectional Encoder Representations from Transformers}{11}{subsection.2.4}%
\contentsline {section}{\numberline {3}Application}{12}{section.3}%
\contentsline {subsection}{\numberline {3.1}Information About the Dataset}{12}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Preparation of the Dataset}{13}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Skip-Gram Algorithm}{13}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Continuous Bag of Words}{13}{subsection.3.4}%
\contentsline {section}{\numberline {4}Analysis and Visualization}{13}{section.4}%
\contentsline {section}{\numberline {5}Discussion}{13}{section.5}%
