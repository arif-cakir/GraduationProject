\babel@toc {american}{}\relax 
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}%
\contentsline {section}{\numberline {2}Word Embedding Techniques}{3}{section.2}%
\contentsline {subsection}{\numberline {2.1}Term Frequency - Inverse Document Frequency}{4}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Skip-Gram Algorithm}{5}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Continuous Bag of Words}{6}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Global Vectors for Word Representation}{8}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Bidirectional Encoder Representations from Transformers}{10}{subsection.2.5}%
\contentsline {section}{\numberline {3}Word2Vec}{12}{section.3}%
\contentsline {subsection}{\numberline {3.1}Autoencoders}{12}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Word2Vec}{13}{subsection.3.2}%
\contentsline {section}{\numberline {4}Application}{14}{section.4}%
\contentsline {subsection}{\numberline {4.1}Information About the Dataset}{14}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Application}{14}{subsection.4.2}%
\contentsline {section}{\numberline {5}Discussion}{26}{section.5}%
\contentsline {section}{\numberline {6}Conclusion}{26}{section.6}%
